{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7cd3237",
   "metadata": {},
   "source": [
    "**CHC_script**\n",
    "\n",
    "The objectives of this script are to:\n",
    "1. Scrape NACHC website for all PDFs\n",
    "2. Convert PDFs to RTFs\n",
    "3. Scrape RTFs for all street addresses\n",
    "4. Batch geocode street addresses and export out to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbcfcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import striprtf\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44bbf2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded MD01.pdf to ../misc/CHC_pdf\n",
      "Downloaded MD02.pdf to ../misc/CHC_pdf\n",
      "Downloaded MD03.pdf to ../misc/CHC_pdf\n",
      "Downloaded MD04.pdf to ../misc/CHC_pdf\n",
      "Downloaded MD05.pdf to ../misc/CHC_pdf\n",
      "Downloaded MD06.pdf to ../misc/CHC_pdf\n",
      "Downloaded MD07.pdf to ../misc/CHC_pdf\n",
      "Downloaded MD08.pdf to ../misc/CHC_pdf\n"
     ]
    }
   ],
   "source": [
    "## \"scraping\" the NACHC website for all congressional district map PDFs\n",
    "\n",
    "# website: https://www.nachc.org/state-level-data-maps/\n",
    "# clicking on a state shows a pop-up window, clicking on congressional district pdf icon directs to new tab w/ download URL\n",
    "\n",
    "state_districts = { # some states missing in this dictionary due to manual testing/downloading, add as necessary\n",
    "    \"FL\": 28,\n",
    "    \"GA\": 14,\n",
    "    \"HI\": 2,\n",
    "    \"ID\": 2,\n",
    "    \"IL\": 17,\n",
    "    \"IN\": 9,\n",
    "    \"IA\": 4,\n",
    "    \"KS\": 4,\n",
    "    \"KY\": 6,\n",
    "    \"LA\": 6,\n",
    "    \"ME\": 2,\n",
    "    \"MA\": 9,\n",
    "    \"MD\": 8,\n",
    "    \"MI\": 13,\n",
    "    \"MN\": 8,\n",
    "    \"MS\": 4,\n",
    "    \"MO\": 8,\n",
    "    \"MT\": 2,\n",
    "    \"NE\": 3,\n",
    "    \"NV\": 4,\n",
    "    \"NH\": 2,\n",
    "    \"NJ\": 12,\n",
    "    \"NM\": 3,\n",
    "    \"NY\": 26,\n",
    "    \"NC\": 14,\n",
    "    \"OH\": 15,\n",
    "    \"OK\": 5,\n",
    "    \"OR\": 6,\n",
    "    \"PA\": 17,\n",
    "    \"RI\": 2,\n",
    "    \"SC\": 7,\n",
    "    \"TN\": 9,\n",
    "    \"TX\": 38,\n",
    "    \"UT\": 4,\n",
    "    \"VA\": 11,\n",
    "    \"WA\": 10,\n",
    "    \"WV\": 2,\n",
    "    \"WI\": 8\n",
    "}\n",
    "\n",
    "base_url = \"https://www.nachc.org/wp-content/uploads/2023/02\"\n",
    "# download_dir = \"../misc/CHC_pdf\"  ## specify download directory here, best to download in misc folder, not data folder\n",
    "\n",
    "def download_congressional_district_pdfs(state_code, num_districts, base_url, download_dir):\n",
    "    for district in range(1, num_districts + 1):\n",
    "        district_code = str(district).zfill(2)\n",
    "        pdf_url = f\"{base_url}/{state_code}{district_code}.pdf\"\n",
    "        response = requests.get(pdf_url)\n",
    "        if response.status_code == 200:\n",
    "            file_name = f\"{state_code}{district_code}.pdf\"\n",
    "            file_path = os.path.join(download_dir, file_name)\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded {file_name} to {download_dir}\")\n",
    "        else:\n",
    "            print(f\"PDF not found for {state_code} District {district_code}\")\n",
    "            \n",
    "for state_code, num_districts in state_districts.items():\n",
    "    download_congressional_district_pdfs(state_code, num_districts, base_url, download_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b3524e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined PDFs for OH into ../data/CHC_data/OH_combined.rtf\n"
     ]
    }
   ],
   "source": [
    "## combining PDFs of the same state into a RTF\n",
    "\n",
    "states = [ # some states missing in this list due to manual testing/downloading, add as necessary\n",
    "    \"CT\",\n",
    "    \"DC\",\n",
    "    \"DE\",\n",
    "    \"FL\",\n",
    "    \"GA\",\n",
    "    \"HI\",\n",
    "    \"ID\",\n",
    "    \"IL\",\n",
    "    \"IN\",\n",
    "    \"IA\",\n",
    "    \"KS\",\n",
    "    \"KY\",\n",
    "    \"LA\",\n",
    "    \"ME\",\n",
    "    \"MA\",\n",
    "    \"MD\",\n",
    "    \"MI\",\n",
    "    \"MN\",\n",
    "    \"MS\",\n",
    "    \"MO\",\n",
    "    \"MT\",\n",
    "    \"NE\",\n",
    "    \"ND\",\n",
    "    \"NV\",\n",
    "    \"NH\",\n",
    "    \"NJ\",\n",
    "    \"NM\",\n",
    "    \"NY\",\n",
    "    \"NC\",\n",
    "    \"OH\",\n",
    "    \"OK\",\n",
    "    \"OR\",\n",
    "    \"PA\",\n",
    "    \"RI\",\n",
    "    \"SC\",\n",
    "    \"SD\",\n",
    "    \"TN\",\n",
    "    \"TX\",\n",
    "    \"UT\",\n",
    "    \"VA\",\n",
    "    \"VT\",\n",
    "    \"WA\",\n",
    "    \"WV\",\n",
    "    \"WI\",\n",
    "    \"WY\"\n",
    "]\n",
    "\n",
    "# download_dir = \"../origination/directory\" ## change to where PDFs are stored\n",
    "# final_dir = \"../data/CHC_data\" ## change to download directory\n",
    "\n",
    "def combine_pdfs_to_rtf(state_code, download_dir, final_dir):\n",
    "    pdf_files = [file for file in os.listdir(download_dir) if file.startswith(state_code) and file.endswith('.pdf')]\n",
    "    pdf_files.sort()\n",
    "\n",
    "    combined_text = \"\"\n",
    "    for pdf_file in pdf_files:\n",
    "        file_path = os.path.join(download_dir, pdf_file)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page_num, page in enumerate(pdf_reader.pages):\n",
    "                if page_num == 0:  # skip the first page\n",
    "                    continue\n",
    "                combined_text += page.extract_text()\n",
    "\n",
    "    rtf_file_name = f\"{state_code}_combined.rtf\"\n",
    "    rtf_file_path = os.path.join(final_dir, rtf_file_name)\n",
    "    document = Document()\n",
    "    document.add_paragraph(combined_text)\n",
    "    document.save(rtf_file_path)\n",
    "    print(f\"Combined PDFs for {state_code} into {rtf_file_path}\")\n",
    "    \n",
    "for state_code in states:\n",
    "     combine_pdfs_to_rtf(state_code, download_dir, final_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d1eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning text data from combined RTF for street addresses\n",
    "\n",
    "def extract_addresses_from_rtfs(folder_path):\n",
    "    addresses = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".rtf\"):\n",
    "            rtf_path = os.path.join(folder_path, filename)\n",
    "            with open(rtf_path, encoding = \"utf-8\") as infile:\n",
    "                content = infile.read()\n",
    "                text = rtf_to_text(content)\n",
    "                pattern = r\"(?<=\\|)\\s*([^|]+)\\s*\\|\"\n",
    "                addresses_dirty = re.findall(pattern, text)\n",
    "                pattern1 = r\"(?<!\\d)\\d{1,5}\\s+[^\\d\\n]+\\s*\\d{5}(?:-\\d{4})?\"\n",
    "                addresses_clean = re.findall(pattern1, \"\\n\".join(addresses_dirty), re.MULTILINE)\n",
    "                addresses.extend([addr.strip() for addr in addresses_clean if addr.strip()])\n",
    "                # addresses.append(addresses_clean)\n",
    "    return addresses\n",
    "\n",
    "# addresses = extract_addresses_from_rtfs(\"../data/CHC_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c158d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## geocoding in \"batches\", writing out into .csv\n",
    "\n",
    "items = addresses  # list of 13,290 items\n",
    "\n",
    "chunk_size = len(items) // 30  # chunking up data\n",
    "\n",
    "result = [items[i:i+chunk_size] for i in range(0, len(items), chunk_size)]\n",
    "\n",
    "# final_dir = \"../data/CHC_data/geocode\" \n",
    "    \n",
    "def process_sublist(sublist):\n",
    "    geocodes = gpd.tools.geocode(sublist, timeout=100)\n",
    "    \n",
    "    geocode_name = f\"geocodes_{sublist[0]}_{sublist[-1]}.csv\"  \n",
    "    geocode_path = os.path.join(final_dir, geocode_name)  \n",
    "    geocodes.to_csv(geocode_path, index=False)  \n",
    "    \n",
    "for sublist in result:\n",
    "    process_sublist(sublist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
